<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>LLM Fine-tuning — FAQs</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">LLM Fine-tuning — FAQs</h1>
</header>
<section data-field="subtitle" class="p-summary">
Answering the most common questions I received as an AI consultant
</section>
<section data-field="body" class="e-content">
<section name="7013" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6d15" id="6d15" class="graf graf--h3 graf--leading graf--title"><strong class="markup--strong markup--h3-strong">LLM Fine-Tuning — FAQs</strong></h3><h4 name="4455" id="4455" class="graf graf--h4 graf-after--h3 graf--subtitle">Answering the most common questions I received as an AI consultant</h4><p name="722e" id="722e" class="graf graf--p graf-after--h4">Last year, I posted an article on <a href="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91" data-href="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">fine-tuning large language models (LLMs)</a>. To my surprise, this turned out to be one of my most-read blogs ever, and it led to dozens of conversations with clients about their fine-tuning questions and AI projects. Here, I will summarize these conversations&#39; most frequently asked questions and my responses.</p><figure name="79b6" id="79b6" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*vXJCryqzZcR8Lkc1b-hJ9A.png" data-width="1280" data-height="720" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*vXJCryqzZcR8Lkc1b-hJ9A.png"><figcaption class="imageCaption">Image from Canva.</figcaption></figure></div></div></section><section name="00c4" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="d77d" id="d77d" class="graf graf--h3 graf--leading"><strong class="markup--strong markup--h3-strong">What is Fine-tuning?</strong></h3><p name="3d91" id="3d91" class="graf graf--p graf-after--h3">I like to define <a href="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91" data-href="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">fine-tuning</strong></a> as <strong class="markup--strong markup--p-strong">taking an existing (pre-trained) model and training at least 1 model parameter to adapt it to a particular use case</strong>.</p><p name="2560" id="2560" class="graf graf--p graf-after--p">It’s important to note the “<em class="markup--em markup--p-em">training at least 1 model parameter</em>” part of the definition. Some will define fine-tuning without this nuance (including me at times). However, this distinguishes fine-tuning from approaches like prompt engineering or prefix-tuning, which adapt a model’s behavior without modifying its internal operations.</p><div name="92d9" id="92d9" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91" data-href="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91"><strong class="markup--strong markup--mixtapeEmbed-strong">Fine-Tuning Large Language Models (LLMs)</strong><br><em class="markup--em markup--mixtapeEmbed-em">A conceptual overview with example Python code</em>towardsdatascience.com</a><a href="https://towardsdatascience.com/fine-tuning-large-language-models-llms-23473d763b91" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="c9fbb0f5ce2055b814fc0009112a88cf" data-thumbnail-img-id="1*YHNrnuaHtS2meh39gGmCCw.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*YHNrnuaHtS2meh39gGmCCw.png);"></a></div><h3 name="67d1" id="67d1" class="graf graf--h3 graf-after--mixtapeEmbed"><strong class="markup--strong markup--h3-strong">When NOT to Fine-tune</strong></h3><p name="f080" id="f080" class="graf graf--p graf-after--h3">People tend to think that LLM engineering techniques like prompt engineering, RAG, and fine-tuning all live on a spectrum, where fine-tuning is an objectively more powerful version of these other approaches. <strong class="markup--strong markup--p-strong">However, this is misleading</strong>.</p><p name="6050" id="6050" class="graf graf--p graf-after--p">The effectiveness of any approach <strong class="markup--strong markup--p-strong">will depend on the details of the use case</strong>. For example, fine-tuning is less effective than <a href="https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac" data-href="https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">retrieval augmented generation (RAG)</a> to provide LLMs with specialized knowledge [1].</p><p name="b854" id="b854" class="graf graf--p graf-after--p">This makes sense when we consider training data volume. For instance, Llama 3.1 8B was trained on ~15T tokens <em class="markup--em markup--p-em">(~1M novels)</em> [2]. A <em class="markup--em markup--p-em">robust</em> fine-tuning dataset might be 1M tokens (1,000 examples consisting of ~1000 tokens each), which is about <strong class="markup--strong markup--p-strong">10 million times smaller</strong>! Thus, any <em class="markup--em markup--p-em">knowledge</em> from a fine-tuning dataset is negligible compared to what was learned at pre-training.</p><h3 name="8a04" id="8a04" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">When do I Fine-tune?</strong></h3><p name="ffa2" id="ffa2" class="graf graf--p graf-after--h3">This is not to say that fine-tuning is useless. A central benefit of fine-tuning an AI assistant is <strong class="markup--strong markup--p-strong">lowering inference costs</strong> [3].</p><p name="b9f3" id="b9f3" class="graf graf--p graf-after--p">The standard way of adapting LLM outputs for a particular application is <a href="https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f" data-href="https://towardsdatascience.com/prompt-engineering-how-to-trick-ai-into-solving-your-problems-7ce1ed3b553f" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">prompt engineering</strong></a>. In this method, <strong class="markup--strong markup--p-strong">users craft prompts that elicit helpful responses from the model</strong>. While this provides a simple and flexible way to adjust model responses, effective prompts may require detailed descriptions of the desired task and several examples the model can mimic, like the one shown below.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="markdown" name="aaf6" id="aaf6" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">--Example Prompt (before fine-tuning)--<br /><br />You are an expert sentiment analysis tool. Given a text, classify its <br />sentiment as &quot;Positive,&quot; &quot;Negative,&quot; or &quot;Neutral.&quot; Here are some examples:<br /><br />Examples<br />Text: &quot;I absolutely love the new design of this product! It’s user-friendly <br />and looks amazing.&quot; Sentiment: Positive<br /><br />Text: &quot;The service was terrible. I had to wait for over an hour, and the staff <br />was rude.&quot; Sentiment: Negative<br /><br />Text: &quot;The movie was okay. It wasn&#x27;t particularly exciting, but it wasn’t bad <br />either.&quot; Sentiment: Neutral<br /><br />Text: &quot;I&#x27;m so happy with the customer support I received. They resolved my <br />issue quickly.&quot; Sentiment: Positive<br /><br />Text: &quot;The meal was bland, and I wouldn’t recommend it to anyone.&quot; Sentiment: <br />Negative<br /><br />Text: &quot;The weather is unpredictable today.&quot; Sentiment: Neutral<br /><br />Now analyze the following text:<br />Text: &quot;[Your input text here]&quot; Sentiment:</span></pre><p name="740f" id="740f" class="graf graf--p graf-after--pre">Fine-tuning, on the other hand, can compress prompt sizes by directly training the model on examples. Shorter prompts mean fewer tokens at inference, leading to <strong class="markup--strong markup--p-strong">lower compute costs and faster model responses</strong> [3]. For instance, after fine-tuning, the above prompt could be compressed to the following.</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="markdown" name="0af5" id="0af5" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">--Example Prompt (after fine-tuning)--<br /><br />You are an expert sentiment analysis tool. Given a text, classify its <br />sentiment as &quot;Positive,&quot; &quot;Negative,&quot; or &quot;Neutral.&quot;<br /><br />Analyze the following text:<br />Text: &quot;[Your input text here]&quot; Sentiment:</span></pre><h3 name="68b3" id="68b3" class="graf graf--h3 graf-after--pre"><strong class="markup--strong markup--h3-strong">RAG vs Fine-tuning?</strong></h3><p name="3264" id="3264" class="graf graf--p graf-after--h3">We’ve already mentioned situations where RAG and fine-tuning perform well. However, since this is such a common question, it’s worth reemphasizing when each approach works best.</p><p name="2db6" id="2db6" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">RAG</strong> is when we <strong class="markup--strong markup--p-strong">inject relevant context into an LLM’s input prompt so that it can generate more helpful responses</strong>. For example, if we have a domain-specific knowledge base (e.g., internal company documents and emails), we might identify the items most relevant to the user’s query so that an LLM can synthesize information in an accurate and digestible way.</p><div name="0461" id="0461" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac" data-href="https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac"><strong class="markup--strong markup--mixtapeEmbed-strong">How to Improve LLMs with RAG</strong><br><em class="markup--em markup--mixtapeEmbed-em">A beginner-friendly introduction w/ Python code</em>towardsdatascience.com</a><a href="https://towardsdatascience.com/how-to-improve-llms-with-rag-abdc132f76ac" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="b2b292979262d9c6e0430b8079cbc0b0" data-thumbnail-img-id="1*N0Ad_oCIrAyzMYRdH3trqg.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*N0Ad_oCIrAyzMYRdH3trqg.png);"></a></div><p name="2bcb" id="2bcb" class="graf graf--p graf-after--mixtapeEmbed">Here’s high-level guidance on when to use each.</p><ul class="postList"><li name="b0f9" id="b0f9" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">RAG</strong>: necessary knowledge for the task is not commonly known or available on the web but can be stored in a database</li><li name="71b4" id="71b4" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Fine-tuning</strong>: necessary knowledge for the task is already baked into the model, but you want to reduce the prompt size or refine response quality</li><li name="ec9a" id="ec9a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">RAG + Fine-tuning</strong>: the task requires specialized knowledge, and we would like to reduce the prompt size or refine the response quality</li></ul><p name="44a5" id="44a5" class="graf graf--p graf-after--li">Notice that these approaches are not mutually exclusive. In fact, the original RAG system proposed by Facebook researchers used fine-tuning to better use retrieved information for generating responses [4].</p><h3 name="34e8" id="34e8" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">How Do I Pick a Model?</strong></h3><p name="3371" id="3371" class="graf graf--p graf-after--h3">Most state-of-the-art language models are trained in similar ways on similar datasets. Thus, <strong class="markup--strong markup--p-strong">performance differences of comparable models are often negligible across use cases</strong>.</p><p name="d6cf" id="d6cf" class="graf graf--p graf-after--p">However, performance is only one of many considerations important for an AI project. Others include privacy, technical requirements, and cost.</p><h4 name="e4fc" id="e4fc" class="graf graf--h4 graf-after--p"><strong class="markup--strong markup--h4-strong">Open-weights vs closed-weights?</strong></h4><p name="0957" id="0957" class="graf graf--p graf-after--h4">An <strong class="markup--strong markup--p-strong">open-weight model&#39;s parameters are accessible to the public</strong>, while the parameters of a closed-weight model are not.</p><ul class="postList"><li name="2127" id="2127" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Open-weight models</strong>: Llama (Meta), Mistral, Gemma (Google), Phi (Microsoft)</li><li name="c972" id="c972" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Closed-weight models</strong>: GPT 3+ (OpenAI), Claude (Anthropic), Gemini (Google)</li></ul><p name="c154" id="c154" class="graf graf--p graf-after--li">The two main considerations when deciding open-weight vs closed-weight are <strong class="markup--strong markup--p-strong">privacy</strong> and <strong class="markup--strong markup--p-strong">flexibility</strong>. For instance, some projects may have strict controls on where user data can be sent, which may disqualify models accessible only via API.</p><p name="2655" id="2655" class="graf graf--p graf-after--p">On the other hand, some use cases require greater flexibility than those afforded by closed-weight model APIs, such as retraining specific parameters in a model or accessing intermediate model representations.</p><h4 name="50c5" id="50c5" class="graf graf--h4 graf-after--p"><strong class="markup--strong markup--h4-strong">How big?</strong></h4><p name="2e50" id="2e50" class="graf graf--p graf-after--h4">Another key question is how big a model should be used. This comes down to a <strong class="markup--strong markup--p-strong">trade-off between model performance and inference costs</strong>.</p><p name="1c40" id="1c40" class="graf graf--p graf-after--p">The approach I’d recommend is to start big to confirm the desired performance is obtainable, then gradually explore smaller and smaller models until performance drops below what’s required. From here, an evaluation can be made on which size choice provides the greatest ROI based on the use case.</p><h4 name="a179" id="a179" class="graf graf--h4 graf-after--p"><strong class="markup--strong markup--h4-strong">Instruction-tuned or foundation model?</strong></h4><p name="b032" id="b032" class="graf graf--p graf-after--h4">Today’s most popular large language models undergo <strong class="markup--strong markup--p-strong">instruction tuning</strong>. In this process, an <strong class="markup--strong markup--p-strong">initial foundation model is fine-tuned to respond to user queries</strong>.</p><p name="ac16" id="ac16" class="graf graf--p graf-after--p">Most business cases I’ve encountered involved an <strong class="markup--strong markup--p-strong">AI chatbot or assistant</strong>. For these types of applications, <strong class="markup--strong markup--p-strong">instruction-tuned models are the best choice</strong>.</p><p name="0f49" id="0f49" class="graf graf--p graf-after--p">However, there are situations where directly using foundation models may work better. Namely, if the <strong class="markup--strong markup--p-strong">LLM is not used for question-answering or conversational tasks</strong>.</p><h3 name="041f" id="041f" class="graf graf--h3 graf-after--p"><strong class="markup--strong markup--h3-strong">How to Prepare Data for Fine-tuning?</strong></h3><p name="2bc0" id="2bc0" class="graf graf--p graf-after--h3">While much of the attention goes to model leaderboards and fine-tuning approaches, these are secondary to the quality of the training dataset. In other words, the <strong class="markup--strong markup--p-strong">data you use to fine-tune your model will be the key driver of its performance</strong>.</p><p name="c47e" id="c47e" class="graf graf--p graf-after--p">From my experience, most clients are interested in making a “<em class="markup--em markup--p-em">custom chatbot</em>” or “<em class="markup--em markup--p-em">ChatGPT for X</em>.” In these cases, the best fine-tuning approach is so-called <strong class="markup--strong markup--p-strong">supervised fine-tuning</strong>. This consists of <strong class="markup--strong markup--p-strong">generating a set of example query-response pairs</strong> from which a model can be fine-tuned.</p><p name="1ee5" id="1ee5" class="graf graf--p graf-after--p">For example, if I wanted to fine-tune an LLM to respond to viewer questions on YouTube, I would need to gather a set of comments with questions and my associated responses. For a concrete example of this, check out the code walk-through on <a href="https://youtu.be/4RAvJt3fWoI?t=1813" data-href="https://youtu.be/4RAvJt3fWoI?t=1813" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">YouTube</a>.</p><figure name="8f55" id="8f55" class="graf graf--figure graf--iframe graf-after--p"><iframe src="https://www.youtube.com/embed/4RAvJt3fWoI?start=1813&amp;feature=oembed&amp;start=1813" width="700" height="393" frameborder="0" scrolling="no"></iframe></figure><h3 name="8777" id="8777" class="graf graf--h3 graf-after--figure"><strong class="markup--strong markup--h3-strong">Advanced Fine-tuning</strong></h3><p name="2695" id="2695" class="graf graf--p graf-after--h3">Much of this article has focused on fine-tuning large language models to create AI assistants. Despite the popularity of such use cases, this is a relatively narrow application of model fine-tuning.</p><h4 name="2812" id="2812" class="graf graf--h4 graf-after--p">Classification</h4><p name="6a83" id="6a83" class="graf graf--p graf-after--h4">Another way we can <strong class="markup--strong markup--p-strong">fine-tune language models is for classification tasks</strong>, such as classifying support ticket tiers, detecting spam emails, or determining the sentiment of a customer review. A classic fine-tuning approach for this is called <strong class="markup--strong markup--p-strong">transfer learning</strong>, where we <strong class="markup--strong markup--p-strong">replace the head of a language model to perform a new classification task</strong>.</p><h4 name="2b7f" id="2b7f" class="graf graf--h4 graf-after--p">Text Embeddings</h4><p name="190a" id="190a" class="graf graf--p graf-after--h4">Fine-tuning can also be applied to <a href="https://towardsdatascience.com/text-embeddings-classification-and-semantic-search-8291746220be" data-href="https://towardsdatascience.com/text-embeddings-classification-and-semantic-search-8291746220be" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">text embeddings</strong></a>, which are most <strong class="markup--strong markup--p-strong">commonly used today to form vector databases</strong> in RAG systems. A major shortcoming of out-the-shelf text embedding models is that they may not perform well on domain-specific language or jargon. Fine-tuning a text embedding model for a particular domain can help overcome this.</p><h4 name="42f3" id="42f3" class="graf graf--h4 graf-after--p">Compression</h4><p name="9376" id="9376" class="graf graf--p graf-after--h4"><a href="https://towardsdatascience.com/compressing-large-language-models-llms-9f406eea5b5e" data-href="https://towardsdatascience.com/compressing-large-language-models-llms-9f406eea5b5e" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong">Model compression</strong></a> aims to <strong class="markup--strong markup--p-strong">reduce the size of an LLM without sacrificing performance</strong>. While this does not necessarily fit under the fine-tuning definition above, it is in the same spirit of <em class="markup--em markup--p-em">adapting a model</em> for a particular use case. Three popular compression techniques include quantization, pruning, and knowledge distillation.</p><h3 name="52a3" id="52a3" class="graf graf--h3 graf-after--p">What’s Next?</h3><p name="c71c" id="c71c" class="graf graf--p graf-after--h3">Here, I summarized the most common fine-tuning questions I’ve received over the past 12 months. While fine-tuning is not a panacea for all LLM use cases, it has key benefits.</p><p name="fea9" id="fea9" class="graf graf--p graf-after--p graf--trailing">If you have questions that were not covered in the article, drop a comment, and I’ll share my thoughts :)</p></div></div></section><section name="d884" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="ec2c" id="ec2c" class="graf graf--p graf--leading"><strong class="markup--strong markup--p-strong">My website</strong>: <a href="https://www.shawhintalebi.com/" data-href="https://www.shawhintalebi.com/" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://www.shawhintalebi.com/</a></p><div name="4689" id="4689" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://shawhin.medium.com/list/8e009ae3054c" data-href="https://shawhin.medium.com/list/8e009ae3054c" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://shawhin.medium.com/list/8e009ae3054c"><strong class="markup--strong markup--mixtapeEmbed-strong">Large Language Models (LLMs)</strong><br><em class="markup--em markup--mixtapeEmbed-em">A series on how to use LLMs in practice.</em>shawhin.medium.com</a><a href="https://shawhin.medium.com/list/8e009ae3054c" class="js-mixtapeImage mixtapeImage mixtapeImage--mediumCatalog  u-ignoreBlock" data-media-id="e38ca2d0de6aa61d7c09af603d8f43e1" data-thumbnail-img-id="0*d080f2d2f3b81a216239adc0fda3af25b2a4d3d5.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/304/160/0*d080f2d2f3b81a216239adc0fda3af25b2a4d3d5.jpeg);"></a></div><p name="1c31" id="1c31" class="graf graf--p graf-after--mixtapeEmbed">[1] <a href="https://arxiv.org/abs/2312.05934" data-href="https://arxiv.org/abs/2312.05934" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://arxiv.org/abs/2312.05934</a></p><p name="3f4a" id="3f4a" class="graf graf--p graf-after--p">[2] <a href="https://arxiv.org/abs/2407.21783" data-href="https://arxiv.org/abs/2407.21783" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Llama 3 paper</a></p><p name="2bfc" id="2bfc" class="graf graf--p graf-after--p">[3] <a href="https://platform.openai.com/docs/guides/fine-tuning" data-href="https://platform.openai.com/docs/guides/fine-tuning" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">OpenAI API Doc</a></p><p name="fedc" id="fedc" class="graf graf--p graf-after--p graf--trailing">[4] <a href="https://arxiv.org/abs/2005.11401" data-href="https://arxiv.org/abs/2005.11401" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Original RAG paper</a></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@shawhin" class="p-author h-card">Shaw Talebi</a> on <a href="https://medium.com/p/200442827c99"><time class="dt-published" datetime="2024-09-26T03:07:45.844Z">September 26, 2024</time></a>.</p><p><a href="https://medium.com/@shawhin/llm-fine-tuning-faqs-200442827c99" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on December 2, 2024.</p></footer></article></body></html>
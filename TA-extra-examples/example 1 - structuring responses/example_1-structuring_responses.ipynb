{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with LLMs Effectively: Pydantic, Crawl4AI & Instructor\n",
    "\n",
    "## ðŸ“š Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Understand how to structure LLM outputs\n",
    "- Learn how to create data schemas with Pydantic\n",
    "- Master web scraping with LLM-powered extraction using Crawl4AI\n",
    "- Use Instructor for reliable structured outputs from any LLM\n",
    "- Build production-ready AI workflows that validate and handle errors gracefully\n",
    "\n",
    "Libraries we will use:\n",
    "1. Pydantic - defining what your data should look like and ensure that it's valid\n",
    "2. Instructor - patches LLM APIs to return Pydantic objects\n",
    "3. Crawl4ai - convert website html into markdown that LLMs can understand & reduce hallucinations\n",
    "\n",
    "## ðŸŽ¯ The Problem: LLM Outputs Are Unpredictable\n",
    "\n",
    "Large Language Models excel at generating human-like text, but integrating their outputs into structured workflows is challenging. Consider these inconsistent outputs from the same prompt:\n",
    "\n",
    "```python\n",
    "# Attempt 1: LLM returns\n",
    "{\"price\": \"$10.00\", \"name\": \"Widget\", \"sku\": \"W123\"}\n",
    "\n",
    "# Attempt 2: LLM returns  \n",
    "{\"price\": \"ten dollars\", \"name\": \"Widget\"}  # Missing SKU!\n",
    "\n",
    "# Attempt 3: LLM returns\n",
    "{\"cost\": \"$10.00\", \"product_name\": \"Widget\", \"sku\": \"W123\"}  # Different keys!\n",
    "```\n",
    "\n",
    "**This inconsistency breaks production systems.** We need a way to enforce structure and validate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\brick\\desktop\\fast projects\\ai-builders-bootcamp-5\\.venv\\lib\\site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic crawl4ai instructor openai --quiet\n",
    "%pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import List, Optional, Union\n",
    "from datetime import datetime\n",
    "\n",
    "# Core libraries\n",
    "from pydantic import BaseModel, Field, field_validator, ValidationError\n",
    "import instructor\n",
    "import openai\n",
    "\n",
    "# Web scraping\n",
    "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n",
    "from crawl4ai.extraction_strategy import LLMExtractionStrategy\n",
    "from crawl4ai import LLMConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Part 1: Pydantic Fundamentals\n",
    "\n",
    "### What is Pydantic?\n",
    "\n",
    "Pydantic is a data validation library that uses Python type hints to validate data. It acts as a \"data contract\" that ensures your data has the expected structure and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid product: name='Laptop' price=999.99 in_stock=True tags=['electronics', 'computers']\n",
      "JSON representation: {\n",
      "  \"name\": \"Laptop\",\n",
      "  \"price\": 999.99,\n",
      "  \"in_stock\": true,\n",
      "  \"tags\": [\n",
      "    \"electronics\",\n",
      "    \"computers\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Basic Pydantic model\n",
    "class Product(BaseModel):\n",
    "    name: str\n",
    "    price: float\n",
    "    in_stock: bool\n",
    "    tags: List[str] = []\n",
    "\n",
    "# Valid data\n",
    "valid_product = Product(\n",
    "    name=\"Laptop\",\n",
    "    price=999.99,\n",
    "    in_stock=True,\n",
    "    tags=[\"electronics\", \"computers\"]\n",
    ")\n",
    "\n",
    "print(f\"Valid product: {valid_product}\")\n",
    "print(f\"JSON representation: {valid_product.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Error:\n",
      "[\n",
      "  {\n",
      "    \"type\": \"float_parsing\",\n",
      "    \"loc\": [\n",
      "      \"price\"\n",
      "    ],\n",
      "    \"msg\": \"Input should be a valid number, unable to parse string as a number\",\n",
      "    \"input\": \"not a number\",\n",
      "    \"url\": \"https://errors.pydantic.dev/2.11/v/float_parsing\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Let's see what happens with invalid data\n",
    "try:\n",
    "    invalid_product = Product(\n",
    "        name=\"Laptop\",\n",
    "        price=\"not a number\",  # This should be a float\n",
    "        in_stock=True\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(\"Validation Error:\")\n",
    "    print(e.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Pydantic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced product: {\n",
      "  \"name\": \"Gaming Laptop\",\n",
      "  \"price\": 1500.0,\n",
      "  \"rating\": 4.5,\n",
      "  \"tags\": [\n",
      "    \"gaming\",\n",
      "    \"electronics\",\n",
      "    \"computers\"\n",
      "  ],\n",
      "  \"created_at\": \"2025-06-13T12:48:03.734700\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class AdvancedProduct(BaseModel):\n",
    "    name: str = Field(..., min_length=1, max_length=100, description=\"Product name\")\n",
    "    price: float = Field(..., gt=0, description=\"Price must be positive\")\n",
    "    rating: Optional[float] = Field(None, ge=1, le=5, description=\"Rating between 1-5\")\n",
    "    tags: List[str] = Field(default_factory=list, description=\"Product tags\")\n",
    "    created_at: datetime = Field(default_factory=datetime.now)\n",
    "    \n",
    "    @field_validator('tags')\n",
    "    def validate_tags(cls, v):\n",
    "        # Custom validation: ensure tags are lowercase\n",
    "        return [tag.lower().strip() for tag in v]\n",
    "    \n",
    "    @field_validator('price')\n",
    "    def validate_price(cls, v):\n",
    "        # Round price to 2 decimal places\n",
    "        return round(v, 2)\n",
    "\n",
    "# Test the advanced model\n",
    "advanced_product = AdvancedProduct(\n",
    "    name=\"Gaming Laptop\",\n",
    "    price=1499.999,  # Will be rounded\n",
    "    rating=4.5,\n",
    "    tags=[\"Gaming\", \"ELECTRONICS\", \" computers \"]  # Will be normalized\n",
    ")\n",
    "\n",
    "print(f\"Advanced product: {advanced_product.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ•·ï¸ Part 2: Web Scraping with Crawl4AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crawl4AI** is a powerful web scraping library specifically designed for the LLM era, handling JavaScript-heavy websites and dynamic content that traditional scrapers struggle with. Unlike conventional scraping tools that require you to manually parse HTML and write complex selectors, Crawl4AI leverages LLMs to intelligently extract structured data from any webpage using natural language instructions. It seamlessly integrates with Pydantic schemas to ensure your scraped data is validated and consistent, making it perfect for building reliable AI-powered data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product schema:\n",
      "{\n",
      "  \"properties\": {\n",
      "    \"name\": {\n",
      "      \"description\": \"Product name from the webpage\",\n",
      "      \"title\": \"Name\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"price\": {\n",
      "      \"description\": \"Current price including currency\",\n",
      "      \"title\": \"Price\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"rating\": {\n",
      "      \"default\": null,\n",
      "      \"description\": \"User rating between 1-5 stars\",\n",
      "      \"title\": \"Rating\",\n",
      "      \"type\": \"number\"\n",
      "    },\n",
      "    \"features\": {\n",
      "      \"description\": \"Key product features\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Features\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"name\",\n",
      "    \"price\",\n",
      "    \"features\"\n",
      "  ],\n",
      "  \"title\": \"Product\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Set your OpenAI API key (get one from https://platform.openai.com)\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Step 1: Define our data contract\n",
    "class Product(BaseModel):\n",
    "    name: str = Field(..., description=\"Product name from the webpage\")\n",
    "    price: str = Field(..., description=\"Current price including currency\")\n",
    "    rating: float = Field(None, description=\"User rating between 1-5 stars\")\n",
    "    features: list[str] = Field(..., description=\"Key product features\")\n",
    "\n",
    "print(\"Product schema:\")\n",
    "print(json.dumps(Product.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Configure the LLM extraction strategy\n",
    "def create_extraction_strategy():\n",
    "    return LLMExtractionStrategy(\n",
    "        llm_config=LLMConfig(\n",
    "            provider=\"openai/gpt-4o-mini\", \n",
    "            api_token=OPENAI_API_KEY\n",
    "        ),\n",
    "        schema=Product.model_json_schema(),\n",
    "        extraction_type=\"schema\",\n",
    "        instruction=\"\"\"\n",
    "            Extract product details from this e-commerce page. \n",
    "            Be precise with pricing (include currency symbols).\n",
    "            If information is not available, use null for optional fields.\n",
    "            Extract features as a list of key product characteristics.\n",
    "        \"\"\",\n",
    "        chunk_token_threshold=2048,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Execute the scraping\n",
    "async def scrape_product(url: str) -> Optional[Product]:\n",
    "    \"\"\"\n",
    "    Scrape a product page and return structured data\n",
    "    \"\"\"\n",
    "    browser_config = BrowserConfig(\n",
    "        headless=True,\n",
    "        verbose=False,\n",
    "        extra_args=[\"--disable-gpu\", \"--no-sandbox\"]\n",
    "    )\n",
    "    \n",
    "    crawl_config = CrawlerRunConfig(\n",
    "        extraction_strategy=create_extraction_strategy(),\n",
    "        cache_mode=CacheMode.BYPASS,\n",
    "        word_count_threshold=50\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        async with AsyncWebCrawler(config=browser_config) as crawler:\n",
    "            result = await crawler.arun(url=url, config=crawl_config)\n",
    "            \n",
    "            if result.success and result.extracted_content:\n",
    "                # Parse and validate with Pydantic\n",
    "                product_data = Product.model_validate_json(result.extracted_content)\n",
    "                return product_data\n",
    "            else:\n",
    "                print(f\"Scraping failed: {result.error_message}\")\n",
    "                return None\n",
    "                \n",
    "    except ValidationError as e:\n",
    "        print(f\"Data validation failed: {e}\")\n",
    "        print(f\"Raw extracted content: {result.extracted_content}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: \n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "product = await scrape_product(\"https://www.amazon.com/stores/page/A0F96D7A-62B9-40A6-B9FF-6143D9E58BFC\")\n",
    "if product:\n",
    "    print(f\"Extracted product: {product.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why this isn't working in the Jupyter notebook, see ```example_1-webscraping.py```\n",
    "\n",
    "Output:\n",
    "```\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Beats Powerbeats Pro 2 Wireless Bluetooth Earbuds - Noise Cancelling, Heart Rate Monitor, IPX4, Up to 45H Battery & Charging Case, Works with Apple & Android - Jet Black\",\n",
    "        \"price\": \"$199.95\",\n",
    "        \"rating\": null,\n",
    "        \"features\": [\n",
    "            \"Noise Cancelling\",\n",
    "            \"Heart Rate Monitor\",\n",
    "            \"IPX4 Water Resistance\",\n",
    "            \"Up to 45H Battery Life\",\n",
    "            \"Charging Case\",\n",
    "            \"Compatible with Apple & Android\"\n",
    "        ],\n",
    "        \"error\": false\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Beats Powerbeats Pro 2 Wireless Bluetooth Earbuds - Noise Cancelling, Heart Rate Monitor, IPX4, Up to 45H Battery & Charging Case, Works with Apple & Android - Electric Orange\",\n",
    "        \"price\": \"$199.95\",\n",
    "        \"rating\": null,\n",
    "        \"features\": [\n",
    "            \"Noise Cancelling\",\n",
    "            \"Heart Rate Monitor\",\n",
    "            \"IPX4 Water Resistance\",\n",
    "            \"Up to 45H Battery Life\",\n",
    "            \"Charging Case\",\n",
    "            \"Compatible with Apple & Android\"\n",
    "        ],\n",
    "        \"error\": false\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Part 3: Instructor for Direct LLM Integration\n",
    "\n",
    "Instructor is another powerful library that patches OpenAI's API to return structured Pydantic objects directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch the OpenAI client with instructor\n",
    "client = instructor.patch(openai.OpenAI())\n",
    "\n",
    "# Define a response schema\n",
    "class PersonInfo(BaseModel):\n",
    "    name: str = Field(description=\"Person's full name\")\n",
    "    age: int = Field(description=\"Person's age in years\")\n",
    "    occupation: str = Field(description=\"Person's job or profession\")\n",
    "    skills: List[str] = Field(description=\"List of skills or expertise\")\n",
    "    \n",
    "class AnalysisResult(BaseModel):\n",
    "    sentiment: str = Field(description=\"Sentiment: positive, negative, or neutral\")\n",
    "    confidence: float = Field(description=\"Confidence score between 0 and 1\")\n",
    "    key_topics: List[str] = Field(description=\"Main topics discussed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract structured information from unstructured text\n",
    "def analyze_text_with_instructor(text: str) -> AnalysisResult:\n",
    "    \"\"\"\n",
    "    Use instructor to get structured analysis from unstructured text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_model=AnalysisResult,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are an expert text analyst. Extract sentiment, confidence, and key topics from the given text.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": f\"Analyze this text: {text}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with sample text\n",
    "sample_text = \"\"\"\n",
    "    I absolutely love the new smartphone I bought yesterday! \n",
    "    The camera quality is amazing and the battery life exceeds my expectations. \n",
    "    The user interface is intuitive and the build quality feels premium. \n",
    "    However, I wish it had better gaming performance for intensive games.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis: {\n",
      "  \"sentiment\": \"positive\",\n",
      "  \"confidence\": 0.85,\n",
      "  \"key_topics\": [\n",
      "    \"smartphone\",\n",
      "    \"camera quality\",\n",
      "    \"battery life\",\n",
      "    \"user interface\",\n",
      "    \"build quality\",\n",
      "    \"gaming performance\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result = analyze_text_with_instructor(sample_text)\n",
    "if result:\n",
    "    print(f\"Analysis: {result.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation Links\n",
    "- [Pydantic](https://docs.pydantic.dev/)\n",
    "- [Crawl4AI](https://docs.crawl4ai.com/)\n",
    "- [Instructor](https://python.useinstructor.com/)\n",
    "- [Mirascope (Alternative to Instructor)](https://mirascope.com/docs/mirascope)\n",
    "\n",
    "Tutorial for getting around most blockers, captchas & rate limits: \n",
    "- https://youtu.be/Htb_NsGlbgc?si=n9JWb6Na2zKoFh-z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d5143b-d5b4-4788-befb-50da4c3f3f97",
   "metadata": {},
   "source": [
    "# YouTube Agent with OpenAI Agents SDK\n",
    "## ABB #6 - Session 4\n",
    "\n",
    "Code authored by: Shaw Talebi\n",
    "\n",
    "**Resources**\n",
    "- [YouTube video](https://youtu.be/-BUs1CPHKfU)\n",
    "- [Blog post](https://medium.com/@shawhin/how-to-improve-llms-with-tools-69cc68c804ed?sk=3ffd8308ce4905617b136a02cfa8dd83)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23470da-9b3e-44a8-b18a-4ccc8f5ba32a",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7514679-c195-4bf9-bad3-0f7a26a0d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import re\n",
    "from agents import Agent, function_tool, Runner\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from dotenv import load_dotenv\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a67ebc-ae9f-4857-bcd9-88b7b5341df5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# Suppress httpx INFO logs to reduce console output\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777be3cb-f501-45c1-a97d-064bbc73b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbe3d3-a590-45eb-be46-52791873b23f",
   "metadata": {},
   "source": [
    "### define instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d50a5039-d46a-4cbb-90a0-22999a164df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You provide help with tasks related to YouTube videos.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb81b6f-aa66-425c-b1a9-d099f0c82c45",
   "metadata": {},
   "source": [
    "### define tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d186d1d6-2950-4cec-8bda-d44321dbbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_tool\n",
    "def fetch_youtube_transcript(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract transcript with timestamps from a YouTube video URL and format it for LLM consumption\n",
    "    \n",
    "    Args:\n",
    "        url (str): YouTube video URL\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted transcript with timestamps, where each entry is on a new line\n",
    "             in the format: \"[MM:SS] Text\"\n",
    "    \"\"\"\n",
    "    # Extract video ID from URL\n",
    "    video_id_pattern = r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*'\n",
    "    video_id_match = re.search(video_id_pattern, url)\n",
    "    \n",
    "    if not video_id_match:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "    \n",
    "    video_id = video_id_match.group(1)\n",
    "    \n",
    "    try:\n",
    "        ytt_api = YouTubeTranscriptApi()\n",
    "        transcript = ytt_api.fetch(video_id)\n",
    "        \n",
    "        # Format each entry with timestamp and text\n",
    "        formatted_entries = []\n",
    "        for entry in transcript:\n",
    "            # Convert seconds to MM:SS format\n",
    "            minutes = int(entry.start // 60)\n",
    "            seconds = int(entry.start % 60)\n",
    "            timestamp = f\"[{minutes:02d}:{seconds:02d}]\"\n",
    "            \n",
    "            formatted_entry = f\"{timestamp} {entry.text}\"\n",
    "            formatted_entries.append(formatted_entry)\n",
    "        \n",
    "        # Join all entries with newlines\n",
    "        return \"\\n\".join(formatted_entries)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error fetching transcript: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e213b4-c41b-4dc8-9213-c79ae13b2108",
   "metadata": {},
   "source": [
    "### create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a0ce90-c098-44e9-a823-182e71576bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"YouTube Transcript Agent\",\n",
    "    instructions=instructions,\n",
    "    tools=[fetch_youtube_transcript],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae7380-3e0d-4846-8fff-abb2d462bdb8",
   "metadata": {},
   "source": [
    "### main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86d9958-aeeb-49cd-9270-6b53b6929aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    input_items = []\n",
    "\n",
    "    print(\"=== YouTube Transcript Agent ===\")\n",
    "    print(\"Type 'exit' to end the conversation\")\n",
    "    print(\"Ask me anything about YouTube videos!\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        input_items.append({\"content\": user_input, \"role\": \"user\"})\n",
    "        \n",
    "        # Check for exit command\n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"\\nGoodbye!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        print(\"\\nAgent: \", end=\"\", flush=True)\n",
    "        result = Runner.run_streamed(\n",
    "            agent,\n",
    "            input=input_items,\n",
    "        )\n",
    "\n",
    "        async for event in result.stream_events(): # not all events are available at outset, hence the async\n",
    "            # We'll ignore the raw responses event deltas\n",
    "            if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "                print(event.data.delta, end=\"\", flush=True)\n",
    "            elif event.type == \"run_item_stream_event\":\n",
    "                if event.item.type == \"tool_call_item\":\n",
    "                    print(\"\\n-- Fetching transcript...\")\n",
    "                elif event.item.type == \"tool_call_output_item\":\n",
    "                    input_items.append({\"content\": f\"Transcript:\\n{event.item.output}\", \"role\": \"system\"})\n",
    "                    print(\"-- Transcript fetched.\")\n",
    "                elif event.item.type == \"message_output_item\":\n",
    "                    input_items.append({\"content\": f\"{event.item.raw_item.content[0].text}\", \"role\": \"assistant\"})\n",
    "                else:\n",
    "                    pass  # Ignore other event types\n",
    "\n",
    "        print(\"\\n\")  # Add a newline after each response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d78925-f897-43dd-8497-87760fa01983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YouTube Transcript Agent ===\n",
      "Type 'exit' to end the conversation\n",
      "Ask me anything about YouTube videos!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  what is this video about? https://youtu.be/ZaY5_ScmiFE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: \n",
      "-- Fetching transcript...\n",
      "-- Transcript fetched.\n",
      "**Summary of the Video: \"What is an AI Agent? (2025: The Year of AI Agents)\"**  \n",
      "[https://youtu.be/ZaY5_ScmiFE](https://youtu.be/ZaY5_ScmiFE)\n",
      "\n",
      "**Host:** Shaw\n",
      "\n",
      "**Overview:**\n",
      "This is the first video in a series about AI agents. Shaw introduces what AI agents are, why they matter, and the different kinds of AI agents you'll encounter.\n",
      "\n",
      "---\n",
      "\n",
      "### Key Points:\n",
      "\n",
      "#### 1. **What is an AI Agent?**\n",
      "- **2025 is being called “the year of the AI agent.”**\n",
      "- There is no single, agreed-upon definition of an AI agent. Different organizations provide slightly different perspectives:\n",
      "    - **OpenAI:** An agent is a large language model (LLM) with instructions and tools.\n",
      "    - **Hugging Face:** An agent is a system where an LLM executes complex tasks using planning and tools.\n",
      "    - **Anthropic:** An agent is an LLM-based system that autonomously directs its own processes and tool use.\n",
      "\n",
      "#### 2. **Three Key Features of AI Agents:**\n",
      "- **1. LLM Involvement:** \n",
      "  Every definition involves an LLM as the core intelligence.\n",
      "- **2. Tool Use:**\n",
      "  AI agents use various tools (e.g., web search, Python interpreter, APIs, memory modules, GUIs) to extend their capabilities beyond text.\n",
      "- **3. Autonomy / Agency:**\n",
      "  Most definitions include some level of autonomy—ability to plan, get feedback from the real world, and make decisions without needing every detail specified up front.\n",
      "\n",
      "#### 3. **AI Agents vs. Chatbots:**\n",
      "- Chatbots (like early ChatGPT) are limited to scripted interactions within a text-box. \n",
      "- **AI agents** can do more because they can interact with reality (e.g., search the web, send emails, run code, access live data) and perform tasks more autonomously.\n",
      "\n",
      "#### 4. **Levels of Agency:**\n",
      "Shaw suggests thinking about \"agency\" as a spectrum, and describes three levels:\n",
      "- **Level 1: LLM + Tools:** (matches OpenAI's definition) A single model that can use some tools, like web search or running code. Good for simple or one-off tasks.\n",
      "- **Level 2: LLM Workflows:** Multiple LLMs (and/or tools) linked together in a workflow or pipeline. Examples include multi-step email responders, blog post writers using step-by-step roles (idea generator, evaluator, writer), etc. This design allows more complex tasks by splitting or routing work.\n",
      "- **Level 3: LLM in a Loop:** A system where an LLM’s output is continuously evaluated and improved based on feedback loops. For example, generating social media posts and iterating until the output passes all desired checks. This is the highest agency because the system can keep improving responses until a stopping rule is met.\n",
      "\n",
      "#### 5. **Design Patterns for Agentic Workflows:** (per Anthropic’s blog)\n",
      "- **Chaining:** Sequential steps (A → B → C)\n",
      "- **Routing:** Branching based on decisions (junk or not junk)\n",
      "- **Parallelization:** Doing subtasks simultaneously (e.g., LLM responds + filters for rule violations)\n",
      "- **Voting:** Multiple LLMs give answers, results aggregated\n",
      "- **Orchestrator-Workers:** A “planner” LLM delegates work to specialized sub-LLMs or code modules\n",
      "- **Evaluator-Optimizer (Loop):** LLM generates output, which is evaluated and iteratively refined\n",
      "\n",
      "#### 6. **Advantages and Practical Uses:**\n",
      "- Real-world feedback and tool use make agents far more powerful than classic chatbots.\n",
      "- Systems with higher agency can tackle open-ended and novel tasks with much less human guidance or scripted logic.\n",
      "- Examples include smarter email inboxes, blog writers, knowledge base assistants, and more.\n",
      "\n",
      "---\n",
      "\n",
      "**What’s next?**\n",
      "- This video is an introduction; future videos will build and demo concrete agent systems at each agency level.\n",
      "\n",
      "---\n",
      "\n",
      "**Who is this video for?**\n",
      "- Anyone curious about what all the “AI agent” hype means, especially those in tech, product, or business roles thinking about practical applications.\n",
      "- Developers looking for a conceptual overview before diving into code or frameworks.\n",
      "\n",
      "---\n",
      "\n",
      "**In summary:**  \n",
      "The video gives a high-level foundation for understanding what AI agents are (focusing on LLMs + tools + autonomy), why they’re important, and how they are different from traditional chatbots—demonstrating agency as a spectrum through real-world examples and common design patterns.\n",
      "\n",
      "If you want the detailed transcript with timestamps or a technical deep dive, let me know!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Can you write me a LinkedIn post about the design patterns?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: Absolutely! Here’s a LinkedIn post summarizing the design patterns for building AI agent workflows, inspired by the video:\n",
      "\n",
      "---\n",
      "\n",
      "🚀 **Unlocking the Power of AI Agents: Essential Design Patterns for Workflows**\n",
      "\n",
      "As AI agents move from hype to reality, understanding how to structure them is key for building robust, reliable, and scalable solutions. Recently, I reviewed several common **design patterns** used in agentic workflows—here’s a quick breakdown that can help teams design smarter, more autonomous LLM-powered systems:\n",
      "\n",
      "🔗 **Chaining:**  \n",
      "Think assembly lines. Each module does a specific task and hands its output to the next step. Perfect for processes like content creation: one module generates ideas, another selects the best, another drafts the post.\n",
      "\n",
      "🛣️ **Routing:**  \n",
      "Branch your workflows. Use agent “decision nodes” to direct different types of inputs down custom paths—for example, sorting incoming emails into “spam,” “easy reply,” and “requires human attention.”\n",
      "\n",
      "⚡ **Parallelization:**  \n",
      "Run subtasks side by side to boost efficiency. Need an answer and a content moderation check? Do both at once, saving valuable time.\n",
      "\n",
      "🗳️ **Voting:**  \n",
      "Boost reliability. Give the same task to multiple agents, then aggregate (“vote”) on responses. This reduces individual model mistakes and delivers more accurate results.\n",
      "\n",
      "🎭 **Orchestrator-Workers:**  \n",
      "Delegate like a manager. One “planner” agent breaks down complex requests and assigns specialized subtasks to “worker” agents, optimizing for flexibility and performance.\n",
      "\n",
      "🔁 **Evaluator-Optimizer (Feedback Loops):**  \n",
      "Embrace iteration. An agent generates output, which is continuously evaluated and refined based on feedback. This enables open-ended, self-improving systems—a hallmark of advanced AI agency.\n",
      "\n",
      "---\n",
      "\n",
      "**Why it matters:**  \n",
      "These patterns aren’t just theory—they’re the blueprints behind today’s emerging AI agent platforms powering automation, content generation, smarter inboxes, and beyond. Learning to combine, chain, and iterate these patterns is crucial for anyone building agents that deliver real-world impact.\n",
      "\n",
      "Are you experimenting with agentic workflows? Which patterns have you found most useful? Let’s share ideas in the comments!\n",
      "\n",
      "#AI #LLM #AIagents #MachineLearning #Automation #Productivity #AIDesign #EmergingTech\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you’d like this post tailored for a specific audience or case!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  That was terrible. Just give me the chapter timestamps for the video.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: Certainly! Here are the main chapters and their corresponding timestamps for the video \"[What is an AI Agent? (2025: The Year of AI Agents)](https://youtu.be/ZaY5_ScmiFE)\":\n",
      "\n",
      "---\n",
      "\n",
      "### Chapter Timestamps\n",
      "\n",
      "- **00:00 – Introduction:**  \n",
      "  Shaw introduces himself and the topic: understanding AI agents.\n",
      "\n",
      "- **00:28 – Why AI Agents Matter & Confusion in Definitions:**  \n",
      "  Discusses the 2025 \"year of AI agents\" and lack of a universal definition.\n",
      "\n",
      "- **00:36 – Definitions from OpenAI, Hugging Face, Anthropic:**  \n",
      "  Reviews how different organizations define AI agents.\n",
      "\n",
      "- **02:00 – Core Features of AI Agents:**  \n",
      "  LLMs, tool use, and autonomy.\n",
      "\n",
      "- **03:36 – Why Agents Are Exciting:**  \n",
      "  The shift from chatbots to agents and the promise of ROI.\n",
      "\n",
      "- **05:16 – Tools Take LLMs into Reality:**  \n",
      "  Importance of tool use and \"test-time compute scaling\".\n",
      "\n",
      "- **06:36 – Agency as a Spectrum:**  \n",
      "  Introduction to agentic systems and levels of agency.\n",
      "\n",
      "- **07:10 – Level 1: LLM + Tools:**  \n",
      "  Simple agentic systems using a single model and tools.\n",
      "\n",
      "- **11:28 – Limitations of Level 1 and Introduction to Level 2:**  \n",
      "  When more complexity is needed.\n",
      "\n",
      "- **11:31 – Level 2: LLM Workflows:**  \n",
      "  Predefined multi-step workflows with multiple LLMs and tools.\n",
      "\n",
      "- **14:01 – Common Workflow Design Patterns:**  \n",
      "  Chaining, routing, parallelization, voting, orchestrator-workers, and evaluator-optimizer.\n",
      "\n",
      "- **19:06 – Level 3: LLM in a Loop (Evaluator-Optimizer):**  \n",
      "  Feedback loops and highly agentic, autonomous systems.\n",
      "\n",
      "- **22:04 – Reinforcement Learning and Real-World Feedback:**  \n",
      "  Fine-tuning and optimizing agents over time.\n",
      "\n",
      "- **22:52 – Series Conclusion & What’s Next:**  \n",
      "  Overview, what to expect in future videos, and call for viewer suggestions.\n",
      "\n",
      "---\n",
      "\n",
      "If you need more specific subtopics or time intervals, let me know!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Please provide links\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent: Here are chapter timestamps from the video \"[What is an AI Agent? (2025: The Year of AI Agents)](https://youtu.be/ZaY5_ScmiFE)\" with clickable links to jump to each section:\n",
      "\n",
      "---\n",
      "\n",
      "### Chapter Timestamps with Links\n",
      "\n",
      "- **[00:00 – Introduction](https://youtu.be/ZaY5_ScmiFE?t=0)**\n",
      "- **[00:28 – Why AI Agents Matter & Confusion in Definitions](https://youtu.be/ZaY5_ScmiFE?t=28)**\n",
      "- **[00:36 – Definitions from OpenAI, Hugging Face, Anthropic](https://youtu.be/ZaY5_ScmiFE?t=36)**\n",
      "- **[02:00 – Core Features of AI Agents](https://youtu.be/ZaY5_ScmiFE?t=120)**\n",
      "- **[03:36 – Why Agents Are Exciting](https://youtu.be/ZaY5_ScmiFE?t=216)**\n",
      "- **[05:16 – Tools Take LLMs into Reality](https://youtu.be/ZaY5_ScmiFE?t=316)**\n",
      "- **[06:36 – Agency as a Spectrum](https://youtu.be/ZaY5_ScmiFE?t=396)**\n",
      "- **[07:10 – Level 1: LLM + Tools](https://youtu.be/ZaY5_ScmiFE?t=430)**\n",
      "- **[11:28 – Limitations of Level 1 and Introduction to Level 2](https://youtu.be/ZaY5_ScmiFE?t=688)**\n",
      "- **[11:31 – Level 2: LLM Workflows](https://youtu.be/ZaY5_ScmiFE?t=691)**\n",
      "- **[14:01 – Common Workflow Design Patterns](https://youtu.be/ZaY5_ScmiFE?t=841)**\n",
      "- **[19:06 – Level 3: LLM in a Loop (Evaluator-Optimizer)](https://youtu.be/ZaY5_ScmiFE?t=1146)**\n",
      "- **[22:04 – Reinforcement Learning and Real-World Feedback](https://youtu.be/ZaY5_ScmiFE?t=1324)**\n",
      "- **[22:52 – Series Conclusion & What’s Next](https://youtu.be/ZaY5_ScmiFE?t=1372)**\n",
      "\n",
      "---\n",
      "\n",
      "Let me know if you want more granular chapters or have follow-up questions!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "await main()\n",
    "# what is this video about? https://youtu.be/ZaY5_ScmiFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04db1009-db50-490f-99d9-4347d2763b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to run in a .py script use\n",
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
